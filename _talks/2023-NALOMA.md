---
title: "Does ChatGPT Resemble Humans in Processing Implicatures?"
collection: talks
type: "Talk"
permalink: /talks/2023-NALOMA
venue: "Natural Logic Meets Machine Learning Workshop for the 15th International Conference on Computational Semantics"
date: 2023-06-20
location: "Nancy, France"
---

[More information here](https://sites.google.com/view/naloma4/program?authuser=0)

Recent advances in large language models (LLMs) and LLM-driven chatbots, such as ChatGPT, have sparked interest in the extent to which these artificial systems possess human-like cognitive abilities. In this study, we assessed ChatGPT's pragmatic capabilities by conducting three preregistered experiments focused on its ability to compute pragmatic implicatures. The first experiment tested whether ChatGPT inhibits the computation of generalized conversational implicatures (GCIs) when explicitly required to process the text's truth-conditional meaning. The second and third experiments examined whether the communicative context affects ChatGPT's ability to compute scalar implicatures (SIs). Our results showed that ChatGPT did not demonstrate human-like flexibility in switching between pragmatic and semantic processing. Additionally, ChatGPT's judgments did not exhibit the well-established effect of communicative context on SI rates.